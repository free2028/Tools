# 代码目的

duplicated_file_check.py: 将多个路径下的文件放在同一个dict中, 比对其md5值, 输出重复的图片文件路径(到指定目录下midfile/duplicates.json)

delete_file.py: 根据上一步检查出的重复图片, 进行删除

# 主要特性：

1. **多线程处理**: 使用 `ThreadPoolExecutor` 实现多线程计算MD5值
2. **支持多种图片格式**: jpg, jpeg, png, gif, bmp, tiff, webp
3. **递归目录扫描**: 自动扫描子目录中的图片文件
4. **内存优化**: 分块读取文件，避免大文件占用过多内存
5. **进度显示**: 显示处理进度
6. **结果排序**: 按MD5值排序显示结果
7. **重复检测**: 找出所有重复的图片并显示路径

# 使用方法：

1. 修改 `main()` 函数中的 `directories` 列表，添加你要扫描的目录路径
2. 可以调整 `max_workers` 参数来控制线程数
3. 运行脚本

## 输出示例：

```shell
扫描目录: /path/to/images
开始处理 1500 个图片文件...
已处理: 100/1500 个文件
已处理: 200/1500 个文件
...
所有文件处理完成！

============================================================
MD5值统计:
============================================================
MD5: 0123456789abcdef...
  -> /path/to/image1.jpg

MD5: 0123456789abcdef...
  -> /path/to/image2.png
  -> /path/to/image3.jpg

============================================================
重复图片检测结果:
============================================================
发现 1 组重复图片:

MD5: 0123456789abcdef...
重复数量: 2
  1. /path/to/image2.png
  2. /path/to/image3.jpg
```

这个工具可以快速找出重复的图片文件，节省存储空间。
